{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>1024</th>\n",
       "      <th>1025</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1017</td>\n",
       "      <td>38</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>889</td>\n",
       "      <td>83</td>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>55</td>\n",
       "      <td>43</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1017</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>-2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1017</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>952</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1   2   3   4   5   6   7   8   9  ...  1016  1017  1018  1019  1020  \\\n",
       "0  0  1017  38  48  51  44  48  56  56  41  ...  84.0  83.0  81.0   NaN   NaN   \n",
       "1  1   889  83  74  65  65  66  55  43  25  ...   NaN   NaN   NaN   NaN   NaN   \n",
       "2  4  1017  19  10  -2  -9  -5   3   8   7  ...  29.0  21.0  16.0   NaN   NaN   \n",
       "3  1  1017  17  29  36  26  21  17  17  13  ... -53.0 -37.0 -33.0   NaN   NaN   \n",
       "4  8   952  77  74  69  70  76  75  76  75  ...   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "   1021  1022  1023  1024  1025  \n",
       "0   NaN   NaN   NaN   NaN   NaN  \n",
       "1   NaN   NaN   NaN   NaN   NaN  \n",
       "2   NaN   NaN   NaN   NaN   NaN  \n",
       "3   NaN   NaN   NaN   NaN   NaN  \n",
       "4   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 1026 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temp.dropna(axis=1, thresh=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>943</th>\n",
       "      <th>944</th>\n",
       "      <th>945</th>\n",
       "      <th>946</th>\n",
       "      <th>947</th>\n",
       "      <th>948</th>\n",
       "      <th>949</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1017</td>\n",
       "      <td>38</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>889</td>\n",
       "      <td>83</td>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>55</td>\n",
       "      <td>43</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1017</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>-2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1017</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>952</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67630</th>\n",
       "      <td>-1</td>\n",
       "      <td>1024</td>\n",
       "      <td>138</td>\n",
       "      <td>135</td>\n",
       "      <td>123</td>\n",
       "      <td>96</td>\n",
       "      <td>59</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67631</th>\n",
       "      <td>-1</td>\n",
       "      <td>1024</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-7</td>\n",
       "      <td>-12</td>\n",
       "      <td>-11</td>\n",
       "      <td>-17</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67632</th>\n",
       "      <td>-1</td>\n",
       "      <td>1024</td>\n",
       "      <td>96</td>\n",
       "      <td>163</td>\n",
       "      <td>208</td>\n",
       "      <td>179</td>\n",
       "      <td>129</td>\n",
       "      <td>114</td>\n",
       "      <td>140</td>\n",
       "      <td>155</td>\n",
       "      <td>...</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67633</th>\n",
       "      <td>-1</td>\n",
       "      <td>1024</td>\n",
       "      <td>-30</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>80</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67634</th>\n",
       "      <td>-1</td>\n",
       "      <td>1024</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>76</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-92.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-116.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67635 rows × 953 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1    2    3    4    5    6    7    8    9  ...    943   944  \\\n",
       "0      0  1017   38   48   51   44   48   56   56   41  ...   58.0  82.0   \n",
       "1      1   889   83   74   65   65   66   55   43   25  ...    NaN   NaN   \n",
       "2      4  1017   19   10   -2   -9   -5    3    8    7  ...   58.0  55.0   \n",
       "3      1  1017   17   29   36   26   21   17   17   13  ...    1.0  -1.0   \n",
       "4      8   952   77   74   69   70   76   75   76   75  ...   81.0  72.0   \n",
       "...   ..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   ...   \n",
       "67630 -1  1024  138  135  123   96   59   38   11   16  ...  -14.0   5.0   \n",
       "67631 -1  1024    4    5   -7  -12  -11  -17    2   52  ...  114.0  92.0   \n",
       "67632 -1  1024   96  163  208  179  129  114  140  155  ...  -77.0   2.0   \n",
       "67633 -1  1024  -30    4   53   85   84   72   80   85  ...   37.0  34.0   \n",
       "67634 -1  1024   41   27   41   76   88   80   83   76  ...    2.0 -28.0   \n",
       "\n",
       "        945    946    947    948    949    950    951    952  \n",
       "0      96.0   92.0   92.0  103.0  118.0  136.0  146.0  145.0  \n",
       "1       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2      66.0   71.0   74.0   74.0   73.0   64.0   35.0   25.0  \n",
       "3       6.0   22.0   37.0   32.0    6.0   -1.0   16.0   25.0  \n",
       "4      69.0   61.0   57.0   56.0   56.0   65.0   70.0   75.0  \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "67630  25.0   22.0   -3.0  -34.0  -39.0  -35.0  -55.0  -74.0  \n",
       "67631  88.0   89.0   84.0   64.0   65.0   59.0    8.0  -11.0  \n",
       "67632  64.0   70.0   52.0   33.0   13.0   11.0    8.0    2.0  \n",
       "67633  37.0   35.0   35.0   36.0   40.0   49.0   55.0   48.0  \n",
       "67634 -92.0 -126.0 -116.0  -75.0  -26.0    1.0    1.0   10.0  \n",
       "\n",
       "[67635 rows x 953 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temp.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_temp.drop(['1'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>943</th>\n",
       "      <th>944</th>\n",
       "      <th>945</th>\n",
       "      <th>946</th>\n",
       "      <th>947</th>\n",
       "      <th>948</th>\n",
       "      <th>949</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>-2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67630</th>\n",
       "      <td>-1</td>\n",
       "      <td>138</td>\n",
       "      <td>135</td>\n",
       "      <td>123</td>\n",
       "      <td>96</td>\n",
       "      <td>59</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67631</th>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-7</td>\n",
       "      <td>-12</td>\n",
       "      <td>-11</td>\n",
       "      <td>-17</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67632</th>\n",
       "      <td>-1</td>\n",
       "      <td>96</td>\n",
       "      <td>163</td>\n",
       "      <td>208</td>\n",
       "      <td>179</td>\n",
       "      <td>129</td>\n",
       "      <td>114</td>\n",
       "      <td>140</td>\n",
       "      <td>155</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67633</th>\n",
       "      <td>-1</td>\n",
       "      <td>-30</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>80</td>\n",
       "      <td>85</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67634</th>\n",
       "      <td>-1</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>76</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>76</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-92.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-116.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60641 rows × 952 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    2    3    4    5    6    7    8    9   10  ...    943   944   945  \\\n",
       "0      0   38   48   51   44   48   56   56   41   20  ...   58.0  82.0  96.0   \n",
       "2      4   19   10   -2   -9   -5    3    8    7    8  ...   58.0  55.0  66.0   \n",
       "3      1   17   29   36   26   21   17   17   13   17  ...    1.0  -1.0   6.0   \n",
       "4      8   77   74   69   70   76   75   76   75   67  ...   81.0  72.0  69.0   \n",
       "5      4   60   59   59   55   36   18   12   20   23  ...   72.0  71.0  53.0   \n",
       "...   ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   ...   ...   \n",
       "67630 -1  138  135  123   96   59   38   11   16   44  ...  -14.0   5.0  25.0   \n",
       "67631 -1    4    5   -7  -12  -11  -17    2   52   73  ...  114.0  92.0  88.0   \n",
       "67632 -1   96  163  208  179  129  114  140  155  108  ...  -77.0   2.0  64.0   \n",
       "67633 -1  -30    4   53   85   84   72   80   85   65  ...   37.0  34.0  37.0   \n",
       "67634 -1   41   27   41   76   88   80   83   76   60  ...    2.0 -28.0 -92.0   \n",
       "\n",
       "         946    947    948    949    950    951    952  \n",
       "0       92.0   92.0  103.0  118.0  136.0  146.0  145.0  \n",
       "2       71.0   74.0   74.0   73.0   64.0   35.0   25.0  \n",
       "3       22.0   37.0   32.0    6.0   -1.0   16.0   25.0  \n",
       "4       61.0   57.0   56.0   56.0   65.0   70.0   75.0  \n",
       "5       27.0   21.0   25.0   17.0   -7.0  -25.0  -25.0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...  \n",
       "67630   22.0   -3.0  -34.0  -39.0  -35.0  -55.0  -74.0  \n",
       "67631   89.0   84.0   64.0   65.0   59.0    8.0  -11.0  \n",
       "67632   70.0   52.0   33.0   13.0   11.0    8.0    2.0  \n",
       "67633   35.0   35.0   36.0   40.0   49.0   55.0   48.0  \n",
       "67634 -126.0 -116.0  -75.0  -26.0    1.0    1.0   10.0  \n",
       "\n",
       "[60641 rows x 952 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_Y = pd.get_dummies(df_final['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67630</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67631</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67632</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67633</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67634</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60641 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       -1   0   1   2   3   4   5   6   7   8   9\n",
       "0       0   1   0   0   0   0   0   0   0   0   0\n",
       "2       0   0   0   0   0   1   0   0   0   0   0\n",
       "3       0   0   1   0   0   0   0   0   0   0   0\n",
       "4       0   0   0   0   0   0   0   0   0   1   0\n",
       "5       0   0   0   0   0   1   0   0   0   0   0\n",
       "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "67630   1   0   0   0   0   0   0   0   0   0   0\n",
       "67631   1   0   0   0   0   0   0   0   0   0   0\n",
       "67632   1   0   0   0   0   0   0   0   0   0   0\n",
       "67633   1   0   0   0   0   0   0   0   0   0   0\n",
       "67634   1   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "[60641 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.drop(['0'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def normalize(df):\n",
    "    arr = []\n",
    "    for i,r in df.iterrows():\n",
    "        #r = (r - r.min()) / (r.max() - r.min())\n",
    "        #r = r/r.max()\n",
    "        r = (r - r.mean()) / r.std()\n",
    "        arr.append(r)\n",
    "    df = pd.DataFrame(arr)\n",
    "    print(\"Done\")\n",
    "    return df\n",
    "\n",
    "df_final = normalize(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>943</th>\n",
       "      <th>944</th>\n",
       "      <th>945</th>\n",
       "      <th>946</th>\n",
       "      <th>947</th>\n",
       "      <th>948</th>\n",
       "      <th>949</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009216</td>\n",
       "      <td>0.197698</td>\n",
       "      <td>0.254243</td>\n",
       "      <td>0.122305</td>\n",
       "      <td>0.197698</td>\n",
       "      <td>0.348484</td>\n",
       "      <td>0.348484</td>\n",
       "      <td>0.065761</td>\n",
       "      <td>-0.330052</td>\n",
       "      <td>-0.763562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386181</td>\n",
       "      <td>0.838539</td>\n",
       "      <td>1.102414</td>\n",
       "      <td>1.027021</td>\n",
       "      <td>1.027021</td>\n",
       "      <td>1.234352</td>\n",
       "      <td>1.517076</td>\n",
       "      <td>1.856344</td>\n",
       "      <td>2.044826</td>\n",
       "      <td>2.025978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.338030</td>\n",
       "      <td>-0.551126</td>\n",
       "      <td>-0.835254</td>\n",
       "      <td>-1.000995</td>\n",
       "      <td>-0.906286</td>\n",
       "      <td>-0.716867</td>\n",
       "      <td>-0.598481</td>\n",
       "      <td>-0.622158</td>\n",
       "      <td>-0.598481</td>\n",
       "      <td>-0.740544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585385</td>\n",
       "      <td>0.514353</td>\n",
       "      <td>0.774803</td>\n",
       "      <td>0.893190</td>\n",
       "      <td>0.964222</td>\n",
       "      <td>0.964222</td>\n",
       "      <td>0.940544</td>\n",
       "      <td>0.727448</td>\n",
       "      <td>0.040807</td>\n",
       "      <td>-0.195966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.362964</td>\n",
       "      <td>-0.069984</td>\n",
       "      <td>0.100920</td>\n",
       "      <td>-0.143229</td>\n",
       "      <td>-0.265304</td>\n",
       "      <td>-0.362964</td>\n",
       "      <td>-0.362964</td>\n",
       "      <td>-0.460624</td>\n",
       "      <td>-0.362964</td>\n",
       "      <td>-0.265304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.753603</td>\n",
       "      <td>-0.802433</td>\n",
       "      <td>-0.631529</td>\n",
       "      <td>-0.240889</td>\n",
       "      <td>0.125335</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>-0.631529</td>\n",
       "      <td>-0.802433</td>\n",
       "      <td>-0.387379</td>\n",
       "      <td>-0.167644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.030537</td>\n",
       "      <td>0.960459</td>\n",
       "      <td>0.843662</td>\n",
       "      <td>0.867022</td>\n",
       "      <td>1.007178</td>\n",
       "      <td>0.983818</td>\n",
       "      <td>1.007178</td>\n",
       "      <td>0.983818</td>\n",
       "      <td>0.796944</td>\n",
       "      <td>0.773584</td>\n",
       "      <td>...</td>\n",
       "      <td>1.123974</td>\n",
       "      <td>0.913740</td>\n",
       "      <td>0.843662</td>\n",
       "      <td>0.656788</td>\n",
       "      <td>0.563350</td>\n",
       "      <td>0.539991</td>\n",
       "      <td>0.539991</td>\n",
       "      <td>0.750225</td>\n",
       "      <td>0.867022</td>\n",
       "      <td>0.983818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.538847</td>\n",
       "      <td>0.515763</td>\n",
       "      <td>0.515763</td>\n",
       "      <td>0.423427</td>\n",
       "      <td>-0.015171</td>\n",
       "      <td>-0.430685</td>\n",
       "      <td>-0.569189</td>\n",
       "      <td>-0.384516</td>\n",
       "      <td>-0.315264</td>\n",
       "      <td>-0.707694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815857</td>\n",
       "      <td>0.792772</td>\n",
       "      <td>0.377259</td>\n",
       "      <td>-0.222928</td>\n",
       "      <td>-0.361432</td>\n",
       "      <td>-0.269096</td>\n",
       "      <td>-0.453769</td>\n",
       "      <td>-1.007787</td>\n",
       "      <td>-1.423301</td>\n",
       "      <td>-1.423301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67630</th>\n",
       "      <td>0.515012</td>\n",
       "      <td>0.498870</td>\n",
       "      <td>0.434301</td>\n",
       "      <td>0.289023</td>\n",
       "      <td>0.089938</td>\n",
       "      <td>-0.023056</td>\n",
       "      <td>-0.168334</td>\n",
       "      <td>-0.141431</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.132984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302851</td>\n",
       "      <td>-0.200618</td>\n",
       "      <td>-0.093005</td>\n",
       "      <td>-0.109147</td>\n",
       "      <td>-0.243664</td>\n",
       "      <td>-0.410465</td>\n",
       "      <td>-0.437368</td>\n",
       "      <td>-0.415845</td>\n",
       "      <td>-0.523459</td>\n",
       "      <td>-0.625692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67631</th>\n",
       "      <td>-0.449117</td>\n",
       "      <td>-0.436105</td>\n",
       "      <td>-0.592251</td>\n",
       "      <td>-0.657312</td>\n",
       "      <td>-0.644300</td>\n",
       "      <td>-0.722373</td>\n",
       "      <td>-0.475142</td>\n",
       "      <td>0.175466</td>\n",
       "      <td>0.448721</td>\n",
       "      <td>0.214502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982219</td>\n",
       "      <td>0.695951</td>\n",
       "      <td>0.643903</td>\n",
       "      <td>0.656915</td>\n",
       "      <td>0.591854</td>\n",
       "      <td>0.331611</td>\n",
       "      <td>0.344623</td>\n",
       "      <td>0.266551</td>\n",
       "      <td>-0.397069</td>\n",
       "      <td>-0.644300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67632</th>\n",
       "      <td>0.835449</td>\n",
       "      <td>1.732568</td>\n",
       "      <td>2.335110</td>\n",
       "      <td>1.946805</td>\n",
       "      <td>1.277314</td>\n",
       "      <td>1.076466</td>\n",
       "      <td>1.424602</td>\n",
       "      <td>1.625449</td>\n",
       "      <td>0.996127</td>\n",
       "      <td>0.299856</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.480991</td>\n",
       "      <td>-0.423195</td>\n",
       "      <td>0.406975</td>\n",
       "      <td>0.487314</td>\n",
       "      <td>0.246297</td>\n",
       "      <td>-0.008110</td>\n",
       "      <td>-0.275907</td>\n",
       "      <td>-0.302686</td>\n",
       "      <td>-0.342856</td>\n",
       "      <td>-0.423195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67633</th>\n",
       "      <td>-0.980800</td>\n",
       "      <td>-0.431349</td>\n",
       "      <td>0.360506</td>\n",
       "      <td>0.877636</td>\n",
       "      <td>0.861475</td>\n",
       "      <td>0.667552</td>\n",
       "      <td>0.796834</td>\n",
       "      <td>0.877636</td>\n",
       "      <td>0.554429</td>\n",
       "      <td>-0.124304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101941</td>\n",
       "      <td>0.053460</td>\n",
       "      <td>0.101941</td>\n",
       "      <td>0.069620</td>\n",
       "      <td>0.069620</td>\n",
       "      <td>0.085780</td>\n",
       "      <td>0.150422</td>\n",
       "      <td>0.295864</td>\n",
       "      <td>0.392826</td>\n",
       "      <td>0.279704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67634</th>\n",
       "      <td>0.156090</td>\n",
       "      <td>-0.076109</td>\n",
       "      <td>0.156090</td>\n",
       "      <td>0.736586</td>\n",
       "      <td>0.935613</td>\n",
       "      <td>0.802929</td>\n",
       "      <td>0.852685</td>\n",
       "      <td>0.736586</td>\n",
       "      <td>0.471216</td>\n",
       "      <td>0.670244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.490749</td>\n",
       "      <td>-0.988318</td>\n",
       "      <td>-2.049797</td>\n",
       "      <td>-2.613708</td>\n",
       "      <td>-2.447852</td>\n",
       "      <td>-1.767842</td>\n",
       "      <td>-0.955147</td>\n",
       "      <td>-0.507335</td>\n",
       "      <td>-0.507335</td>\n",
       "      <td>-0.358064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60641 rows × 951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              2         3         4         5         6         7         8  \\\n",
       "0      0.009216  0.197698  0.254243  0.122305  0.197698  0.348484  0.348484   \n",
       "2     -0.338030 -0.551126 -0.835254 -1.000995 -0.906286 -0.716867 -0.598481   \n",
       "3     -0.362964 -0.069984  0.100920 -0.143229 -0.265304 -0.362964 -0.362964   \n",
       "4      1.030537  0.960459  0.843662  0.867022  1.007178  0.983818  1.007178   \n",
       "5      0.538847  0.515763  0.515763  0.423427 -0.015171 -0.430685 -0.569189   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "67630  0.515012  0.498870  0.434301  0.289023  0.089938 -0.023056 -0.168334   \n",
       "67631 -0.449117 -0.436105 -0.592251 -0.657312 -0.644300 -0.722373 -0.475142   \n",
       "67632  0.835449  1.732568  2.335110  1.946805  1.277314  1.076466  1.424602   \n",
       "67633 -0.980800 -0.431349  0.360506  0.877636  0.861475  0.667552  0.796834   \n",
       "67634  0.156090 -0.076109  0.156090  0.736586  0.935613  0.802929  0.852685   \n",
       "\n",
       "              9        10        11  ...       943       944       945  \\\n",
       "0      0.065761 -0.330052 -0.763562  ...  0.386181  0.838539  1.102414   \n",
       "2     -0.622158 -0.598481 -0.740544  ...  0.585385  0.514353  0.774803   \n",
       "3     -0.460624 -0.362964 -0.265304  ... -0.753603 -0.802433 -0.631529   \n",
       "4      0.983818  0.796944  0.773584  ...  1.123974  0.913740  0.843662   \n",
       "5     -0.384516 -0.315264 -0.707694  ...  0.815857  0.792772  0.377259   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "67630 -0.141431  0.009228  0.132984  ... -0.302851 -0.200618 -0.093005   \n",
       "67631  0.175466  0.448721  0.214502  ...  0.982219  0.695951  0.643903   \n",
       "67632  1.625449  0.996127  0.299856  ... -1.480991 -0.423195  0.406975   \n",
       "67633  0.877636  0.554429 -0.124304  ...  0.101941  0.053460  0.101941   \n",
       "67634  0.736586  0.471216  0.670244  ... -0.490749 -0.988318 -2.049797   \n",
       "\n",
       "            946       947       948       949       950       951       952  \n",
       "0      1.027021  1.027021  1.234352  1.517076  1.856344  2.044826  2.025978  \n",
       "2      0.893190  0.964222  0.964222  0.940544  0.727448  0.040807 -0.195966  \n",
       "3     -0.240889  0.125335  0.003260 -0.631529 -0.802433 -0.387379 -0.167644  \n",
       "4      0.656788  0.563350  0.539991  0.539991  0.750225  0.867022  0.983818  \n",
       "5     -0.222928 -0.361432 -0.269096 -0.453769 -1.007787 -1.423301 -1.423301  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "67630 -0.109147 -0.243664 -0.410465 -0.437368 -0.415845 -0.523459 -0.625692  \n",
       "67631  0.656915  0.591854  0.331611  0.344623  0.266551 -0.397069 -0.644300  \n",
       "67632  0.487314  0.246297 -0.008110 -0.275907 -0.302686 -0.342856 -0.423195  \n",
       "67633  0.069620  0.069620  0.085780  0.150422  0.295864  0.392826  0.279704  \n",
       "67634 -2.613708 -2.447852 -1.767842 -0.955147 -0.507335 -0.507335 -0.358064  \n",
       "\n",
       "[60641 rows x 951 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr = np.array(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60641, 951)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00921602,  0.19769846,  0.25424319,  0.12230548,  0.19769846,\n",
       "        0.34848441,  0.34848441,  0.06576075, -0.33005238, -0.76356199,\n",
       "       -0.87665146, -0.7258655 , -0.59392779, -0.61277604, -0.59392779,\n",
       "       -0.38659711, -0.2546594 ,  0.00921602,  0.34848441,  0.36733266,\n",
       "        0.27309144,  0.27309144,  0.19769846, -0.00963223,  0.02806426,\n",
       "        0.25424319,  0.25424319,  0.04691251, -0.00963223, -0.06617696,\n",
       "       -0.19811467, -0.23581116, -0.27350764, -0.31120413, -0.23581116,\n",
       "       -0.00963223,  0.10345724,  0.14115373,  0.29193968,  0.36733266,\n",
       "        0.42387739,  0.63120808,  0.66890456,  0.5558151 ,  0.3861809 ,\n",
       "        0.25424319,  0.04691251,  0.04691251,  0.29193968,  0.65005632,\n",
       "        0.95162823,  0.97047647,  0.95162823,  1.0270212 ,  0.95162823,\n",
       "        0.81969052,  1.0270212 ,  1.49822731,  1.63016502,  1.5359238 ,\n",
       "        1.61131677,  1.93173692,  2.0071299 ,  1.93173692,  2.06367463,\n",
       "        2.12021936,  2.19561234,  2.15791585,  1.93173692,  1.76210273,\n",
       "        1.59246853,  1.59246853,  1.79979921,  2.08252288,  2.34639829,\n",
       "        2.478336  ,  2.51603249,  2.34639829,  2.04482639,  1.8374957 ,\n",
       "        1.91288868,  2.19561234,  2.34639829,  2.19561234,  2.02597814,\n",
       "        2.12021936,  2.38409478,  2.42179127,  2.23330883,  1.93173692,\n",
       "        1.81864746,  2.12021936,  2.45948776,  2.23330883,  1.61131677,\n",
       "        1.30974487,  1.40398609,  1.30974487,  1.23435189,  1.23435189,\n",
       "        1.34744135,  1.70555799,  1.85634395,  1.74325448,  1.46053082,\n",
       "        1.10241418,  0.91393174,  1.17780716,  1.63016502,  1.76210273,\n",
       "        1.17780716,  0.49927037,  0.34848441,  0.7254493 ,  1.27204838,\n",
       "        1.70555799,  1.51707555,  1.04586945,  0.53696686,  0.19769846,\n",
       "        0.12230548,  0.19769846,  0.29193968,  0.29193968,  0.19769846,\n",
       "       -0.0850252 , -0.0850252 ,  0.06576075,  0.34848441,  0.61235983,\n",
       "        0.65005632,  0.59351159,  0.59351159,  0.91393174,  1.10241418,\n",
       "        0.80084227,  0.5558151 ,  0.5558151 ,  0.59351159,  0.42387739,\n",
       "        0.29193968,  0.27309144,  0.29193968,  0.31078793,  0.31078793,\n",
       "        0.31078793,  0.44272563,  0.61235983,  0.57466334,  0.57466334,\n",
       "        0.63120808,  0.65005632,  0.59351159,  0.61235983,  0.74429754,\n",
       "        0.7254493 ,  0.53696686,  0.42387739,  0.63120808,  0.57466334,\n",
       "        0.19769846, -0.34890062, -0.34890062,  0.23539495,  0.5558151 ,\n",
       "        0.3861809 ,  0.2165467 ,  0.02806426, -0.06617696,  0.084609  ,\n",
       "        0.5558151 ,  0.80084227,  0.61235983,  0.40502915,  0.32963617,\n",
       "        0.00921602, -0.2546594 , -0.00963223,  0.40502915,  0.61235983,\n",
       "        0.31078793, -0.21696291, -0.40544535, -0.49968657, -0.34890062,\n",
       "       -0.0850252 ,  0.06576075,  0.06576075, -0.06617696, -0.19811467,\n",
       "       -0.23581116, -0.06617696, -0.10387345, -0.61277604, -0.93319619,\n",
       "       -0.7258655 , -0.16041818,  0.06576075, -0.19811467, -0.53738306,\n",
       "       -0.63162428, -0.57507955, -0.55623131, -0.76356199, -0.91434795,\n",
       "       -0.87665146, -0.74471375, -0.82010672, -1.12167863, -1.36670581,\n",
       "       -1.34785756, -1.02743741, -0.83895497, -0.93319619, -0.93319619,\n",
       "       -0.66932077, -0.51853482, -0.63162428, -0.61277604, -0.51853482,\n",
       "       -0.36774886, -0.40544535, -0.48083833, -0.2546594 , -0.21696291,\n",
       "       -0.31120413, -0.33005238, -0.33005238, -0.23581116, -0.17926642,\n",
       "       -0.23581116, -0.31120413, -0.51853482, -0.91434795, -1.40440229,\n",
       "       -1.49864351, -1.34785756, -0.95204443, -0.61277604, -0.40544535,\n",
       "       -0.51853482, -0.74471375, -1.10283039, -1.34785756, -1.17822336,\n",
       "       -0.78241024, -0.63162428, -0.87665146, -1.25361634, -1.46094703,\n",
       "       -1.36670581, -1.12167863, -0.97089268, -0.85780321, -0.74471375,\n",
       "       -0.70701726, -0.91434795, -1.12167863, -1.17822336, -1.42325054,\n",
       "       -1.7059742 , -1.72482244, -1.68712596, -1.68712596, -1.63058122,\n",
       "       -1.42325054, -1.42325054, -1.47979527, -1.47979527, -1.40440229,\n",
       "       -1.36670581, -1.38555405, -1.27246458, -1.25361634, -1.53634   ,\n",
       "       -1.68712596, -1.40440229, -1.02743741, -0.8954997 , -1.14052688,\n",
       "       -1.40440229, -1.36670581, -1.08398214, -0.82010672, -0.66932077,\n",
       "       -0.63162428, -0.57507955, -0.34890062, -0.29235589, -0.31120413,\n",
       "       -0.31120413, -0.53738306, -0.76356199, -0.70701726, -0.68816902,\n",
       "       -0.78241024, -0.8954997 , -0.91434795, -0.80125848, -0.74471375,\n",
       "       -0.66932077, -0.51853482, -0.36774886, -0.36774886, -0.49968657,\n",
       "       -0.38659711, -0.31120413, -0.57507955, -0.83895497, -0.70701726,\n",
       "       -0.40544535, -0.48083833, -0.61277604, -0.65047253, -0.63162428,\n",
       "       -0.65047253, -0.68816902, -0.61277604, -0.38659711, -0.34890062,\n",
       "       -0.53738306, -0.66932077, -0.66932077, -0.66932077, -0.74471375,\n",
       "       -0.83895497, -1.02743741, -1.12167863, -1.21591985, -1.12167863,\n",
       "       -0.95204443, -0.93319619, -0.95204443, -0.80125848, -0.68816902,\n",
       "       -0.51853482, -0.2546594 , -0.19811467, -0.19811467, -0.0850252 ,\n",
       "        0.084609  ,  0.04691251, -0.31120413, -0.7258655 , -0.85780321,\n",
       "       -0.78241024, -0.68816902, -0.76356199, -1.10283039, -1.42325054,\n",
       "       -1.51749176, -1.47979527, -1.36670581, -1.12167863, -0.85780321,\n",
       "       -0.82010672, -0.82010672, -0.63162428, -0.36774886, -0.06617696,\n",
       "        0.34848441,  0.63120808,  0.61235983,  0.5558151 ,  0.59351159,\n",
       "        0.59351159,  0.42387739,  0.19769846,  0.00921602,  0.02806426,\n",
       "        0.12230548,  0.00921602, -0.36774886, -0.59392779, -0.33005238,\n",
       "        0.084609  ,  0.31078793,  0.81969052,  1.14011067,  0.87623525,\n",
       "        0.29193968, -0.00963223,  0.10345724,  0.2165467 , -0.29235589,\n",
       "        0.10345724,  0.80084227,  1.12126242,  1.21550364,  1.44168257,\n",
       "        1.55477204,  1.42283433,  1.14011067,  0.89508349,  0.97047647,\n",
       "        1.30974487,  1.44168257,  1.32859311,  1.21550364,  0.91393174,\n",
       "        0.85738701,  1.17780716,  1.49822731,  1.57362028,  1.47937906,\n",
       "        1.21550364,  0.7254493 ,  0.49927037,  0.5558151 ,  0.5558151 ,\n",
       "        0.51811861,  0.57466334,  0.83853876,  1.10241418,  1.17780716,\n",
       "        0.98932471,  0.87623525,  1.10241418,  1.32859311,  1.34744135,\n",
       "        1.15895891,  0.81969052,  0.40502915,  0.14115373,  0.00921602,\n",
       "       -0.27350764, -0.59392779, -0.80125848, -0.68816902, -0.48083833,\n",
       "       -0.48083833, -0.63162428, -1.02743741, -1.46094703, -1.66827771,\n",
       "       -1.7059742 , -1.8756084 , -1.83791191, -1.7059742 , -1.74367069,\n",
       "       -2.08293908, -2.57299343, -2.94995832, -2.96880656, -2.57299343,\n",
       "       -1.96984962, -1.74367069, -2.02639435, -2.0452426 , -2.06409084,\n",
       "       -1.98869786, -1.72482244, -1.64942947, -1.57403649, -1.40440229,\n",
       "       -1.08398214, -0.76356199, -0.70701726, -0.80125848, -0.63162428,\n",
       "       -0.29235589, -0.00963223,  0.2165467 ,  0.25424319,  0.27309144,\n",
       "        0.27309144,  0.40502915,  0.51811861,  0.3861809 ,  0.36733266,\n",
       "        0.3861809 ,  0.27309144,  0.084609  ,  0.06576075, -0.0850252 ,\n",
       "       -0.34890062, -0.49968657, -0.38659711, -0.06617696,  0.06576075,\n",
       "       -0.29235589, -0.7258655 , -1.04628565, -1.38555405, -1.51749176,\n",
       "       -1.36670581, -1.38555405, -1.85676015, -2.1771803 , -2.13948382,\n",
       "       -2.02639435, -1.95100137, -1.83791191, -1.8756084 , -1.96984962,\n",
       "       -1.83791191, -1.68712596, -1.68712596, -1.64942947, -1.32900932,\n",
       "       -0.80125848, -0.61277604, -0.74471375, -0.91434795, -0.95204443,\n",
       "       -1.19707161, -1.51749176, -1.8756084 , -2.3468145 , -2.62953816,\n",
       "       -2.45990397, -2.25257328, -2.3468145 , -2.44105572, -2.29026977,\n",
       "       -1.81906367, -1.51749176, -1.34785756, -1.25361634, -1.53634   ,\n",
       "       -1.72482244, -1.66827771, -1.72482244, -1.66827771, -1.46094703,\n",
       "       -1.34785756, -1.32900932, -1.36670581, -1.36670581, -1.49864351,\n",
       "       -1.66827771, -1.63058122, -1.36670581, -1.12167863, -1.10283039,\n",
       "       -1.15937512, -1.04628565, -0.85780321, -0.78241024, -0.83895497,\n",
       "       -0.93319619, -1.08398214, -1.36670581, -1.74367069, -2.0452426 ,\n",
       "       -2.06409084, -1.93215313, -1.7059742 , -1.49864351, -1.63058122,\n",
       "       -1.72482244, -1.53634   , -1.15937512, -0.95204443, -1.36670581,\n",
       "       -1.81906367, -2.02639435, -1.81906367, -1.49864351, -1.38555405,\n",
       "       -1.02743741, -0.7258655 , -0.63162428, -0.59392779, -0.51853482,\n",
       "       -0.19811467,  0.06576075,  0.25424319,  0.29193968,  0.00921602,\n",
       "       -0.38659711, -0.57507955, -0.63162428,  0.12230548,  0.27309144,\n",
       "       -0.04732871, -0.21696291, -0.16041818, -0.02848047, -0.27350764,\n",
       "       -0.61277604, -0.63162428, -0.61277604, -0.7258655 , -0.87665146,\n",
       "       -0.85780321, -0.65047253, -0.46199009, -0.38659711, -0.36774886,\n",
       "       -0.23581116,  0.19769846,  0.61235983,  0.59351159,  0.36733266,\n",
       "        0.3861809 ,  0.40502915,  0.31078793,  0.32963617,  0.36733266,\n",
       "        0.31078793,  0.12230548,  0.084609  ,  0.49927037,  0.83853876,\n",
       "        1.00817296,  0.98932471,  0.70660105,  0.29193968,  0.00921602,\n",
       "        0.23539495,  0.40502915,  0.29193968,  0.27309144,  0.40502915,\n",
       "        0.42387739,  0.36733266,  0.44272563,  0.59351159,  0.70660105,\n",
       "        0.95162823,  1.40398609,  1.78095097,  2.0071299 ,  2.08252288,\n",
       "        2.10137112,  2.13906761,  2.06367463,  1.87519219,  1.76210273,\n",
       "        1.79979921,  1.91288868,  1.91288868,  1.72440624,  1.46053082,\n",
       "        1.27204838,  0.65005632,  0.32963617,  0.36733266,  0.5558151 ,\n",
       "        0.57466334,  0.36733266,  0.14115373,  0.04691251,  0.04691251,\n",
       "        0.00921602, -0.0850252 , -0.00963223,  0.12230548,  0.27309144,\n",
       "        0.57466334,  0.68775281,  0.59351159,  0.31078793,  0.00921602,\n",
       "        0.04691251,  0.27309144,  0.3861809 ,  0.3861809 ,  0.14115373,\n",
       "        0.12230548,  0.51811861,  0.91393174,  1.0270212 ,  1.25320013,\n",
       "        1.47937906,  1.5359238 ,  1.44168257,  1.23435189,  1.23435189,\n",
       "        1.49822731,  1.87519219,  1.81864746,  1.25320013,  0.65005632,\n",
       "        0.31078793,  0.3861809 ,  0.66890456,  0.95162823,  0.85738701,\n",
       "        0.36733266,  0.12230548,  0.34848441,  0.89508349,  1.23435189,\n",
       "        1.21550364,  0.98932471,  0.83853876,  0.89508349,  1.00817296,\n",
       "        0.91393174,  0.7254493 ,  0.42387739,  0.10345724,  0.29193968,\n",
       "        0.61235983,  0.53696686,  0.34848441,  0.51811861,  0.89508349,\n",
       "        0.95162823,  0.91393174,  0.80084227,  0.42387739,  0.2165467 ,\n",
       "       -0.0850252 , -0.27350764, -0.00963223,  0.44272563,  0.81969052,\n",
       "        0.80084227,  0.53696686,  0.40502915,  0.49927037,  0.49927037,\n",
       "        0.34848441,  0.27309144,  0.25424319,  0.19769846, -0.0850252 ,\n",
       "       -0.49968657, -0.70701726, -0.82010672, -0.83895497, -0.74471375,\n",
       "       -0.63162428, -0.49968657, -0.29235589, -0.00963223,  0.31078793,\n",
       "        0.59351159,  0.80084227,  0.80084227,  0.74429754,  0.83853876,\n",
       "        0.80084227,  0.61235983,  0.27309144,  0.02806426,  0.06576075,\n",
       "        0.19769846,  0.19769846,  0.25424319,  0.3861809 ,  0.70660105,\n",
       "        0.81969052,  0.7254493 ,  0.74429754,  0.91393174,  0.87623525,\n",
       "        0.65005632,  0.59351159,  0.65005632,  0.65005632,  0.66890456,\n",
       "        0.66890456,  0.66890456,  0.95162823,  1.23435189,  1.25320013,\n",
       "        1.14011067,  0.89508349,  0.63120808,  0.40502915,  0.27309144,\n",
       "        0.29193968,  0.31078793,  0.19769846, -0.2546594 , -0.38659711,\n",
       "       -0.33005238, -0.17926642, -0.17926642, -0.19811467, -0.10387345,\n",
       "       -0.16041818, -0.2546594 , -0.19811467,  0.19769846,  0.53696686,\n",
       "        0.68775281,  0.57466334,  0.29193968,  0.04691251,  0.00921602,\n",
       "        0.084609  ,  0.00921602, -0.33005238, -0.63162428, -0.7258655 ,\n",
       "       -0.65047253, -0.63162428, -0.68816902, -0.65047253, -0.57507955,\n",
       "       -0.46199009, -0.19811467, -0.00963223, -0.04732871, -0.21696291,\n",
       "       -0.29235589, -0.27350764, -0.27350764, -0.21696291, -0.04732871,\n",
       "        0.084609  ,  0.27309144,  0.36733266,  0.2165467 , -0.04732871,\n",
       "       -0.02848047,  0.00921602,  0.04691251,  0.19769846,  0.25424319,\n",
       "        0.04691251, -0.02848047,  0.25424319,  0.63120808,  0.91393174,\n",
       "        1.10241418,  1.0270212 ,  0.91393174,  0.91393174,  1.12126242,\n",
       "        0.98932471,  0.97047647,  0.80084227,  0.65005632,  1.0270212 ,\n",
       "        1.49822731,  1.63016502,  1.61131677,  1.79979921,  2.0071299 ,\n",
       "        1.85634395,  1.74325448,  1.5359238 ,  1.49822731,  1.5359238 ,\n",
       "        1.40398609,  1.0270212 ,  0.74429754,  0.57466334,  0.49927037,\n",
       "        0.53696686,  0.53696686,  0.49927037,  0.51811861,  0.57466334,\n",
       "        0.68775281,  0.5558151 ,  0.42387739,  0.68775281,  0.95162823,\n",
       "        0.85738701,  0.5558151 ,  0.40502915,  0.57466334,  0.49927037,\n",
       "        0.06576075, -0.34890062, -0.61277604, -0.55623131, -0.46199009,\n",
       "       -0.57507955, -0.66932077, -0.68816902, -0.55623131, -0.49968657,\n",
       "       -0.48083833, -0.38659711, -0.34890062, -0.31120413, -0.34890062,\n",
       "       -0.48083833, -0.53738306, -0.63162428, -0.63162428, -0.55623131,\n",
       "       -0.40544535, -0.2546594 , -0.04732871, -0.23581116, -0.33005238,\n",
       "        0.00921602,  0.44272563,  0.65005632,  0.70660105,  0.59351159,\n",
       "        0.27309144,  0.00921602,  0.04691251,  0.27309144,  0.51811861,\n",
       "        0.7254493 ,  0.83853876,  0.53696686,  0.04691251, -0.33005238,\n",
       "       -0.40544535, -0.34890062, -0.31120413, -0.40544535, -0.74471375,\n",
       "       -1.02743741, -0.83895497, -0.38659711, -0.10387345,  0.04691251,\n",
       "        0.12230548, -0.00963223, -0.19811467, -0.31120413, -0.27350764,\n",
       "       -0.19811467, -0.16041818, -0.23581116, -0.33005238, -0.29235589,\n",
       "       -0.21696291, -0.29235589, -0.23581116, -0.16041818, -0.38659711,\n",
       "       -0.66932077, -0.82010672, -0.80125848, -0.74471375, -0.87665146,\n",
       "       -0.91434795, -0.87665146, -0.78241024, -0.63162428, -0.38659711,\n",
       "       -0.16041818, -0.0850252 , -0.17926642, -0.17926642, -0.04732871,\n",
       "        0.04691251,  0.3861809 ,  0.83853876,  1.10241418,  1.0270212 ,\n",
       "        1.0270212 ,  1.23435189,  1.51707555,  1.85634395,  2.04482639,\n",
       "        2.02597814])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_val = []\n",
    "# for val in np_arr:\n",
    "#     #avg = sum(val[1:])/len(val[1:])\n",
    "#     med = sorted(val[1:])\n",
    "#     avg_val.append(med[len(med)//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_X = np_arr\n",
    "total_Y = np.array(total_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00921602,  0.19769846,  0.25424319, ...,  1.85634395,\n",
       "          2.04482639,  2.02597814],\n",
       "        [-0.33803025, -0.551126  , -0.83525366, ...,  0.72744847,\n",
       "          0.04080663, -0.19596642],\n",
       "        [-0.36296397, -0.06998442,  0.10092031, ..., -0.80243329,\n",
       "         -0.38737893, -0.16764427],\n",
       "        ...,\n",
       "        [ 0.83544932,  1.73256789,  2.33511021, ..., -0.30268617,\n",
       "         -0.34285566, -0.42319464],\n",
       "        [-0.98079985, -0.43134938,  0.36050571, ...,  0.29586448,\n",
       "          0.39282633,  0.27970417],\n",
       "        [ 0.15608964, -0.07610896,  0.15608964, ..., -0.50733492,\n",
       "         -0.50733492, -0.3580644 ]]),\n",
       " array([[0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_X, total_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (np.array(df_temp['0'])).reshape(-1,1)\n",
    "total_XY = np.append(labels, total_X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60641, 952)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_XY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save = pd.DataFrame(total_XY)\n",
    "df_save.to_csv(\"preprocess_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(total_X, total_Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48512, 951)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    model = tf.keras.models.Sequential([])\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(200, activation=\"relu\"))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(50, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(11, activation=\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.01), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1365/1365 [==============================] - 18s 13ms/step - loss: 2.3276 - accuracy: 0.2079 - val_loss: 2.2865 - val_accuracy: 0.2232\n",
      "Epoch 2/10\n",
      "1365/1365 [==============================] - 17s 12ms/step - loss: 2.2793 - accuracy: 0.2222 - val_loss: 2.2742 - val_accuracy: 0.2277\n",
      "Epoch 3/10\n",
      "1365/1365 [==============================] - 18s 13ms/step - loss: 2.2682 - accuracy: 0.2242 - val_loss: 2.2735 - val_accuracy: 0.2220\n",
      "Epoch 4/10\n",
      "1365/1365 [==============================] - 13s 9ms/step - loss: 2.2506 - accuracy: 0.2312 - val_loss: 2.2703 - val_accuracy: 0.2279\n",
      "Epoch 5/10\n",
      "1365/1365 [==============================] - 16s 11ms/step - loss: 2.2290 - accuracy: 0.2364 - val_loss: 2.2718 - val_accuracy: 0.2240\n",
      "Epoch 6/10\n",
      "1365/1365 [==============================] - 12s 9ms/step - loss: 2.2066 - accuracy: 0.2428 - val_loss: 2.2663 - val_accuracy: 0.2253\n",
      "Epoch 7/10\n",
      "1365/1365 [==============================] - 19s 14ms/step - loss: 2.1785 - accuracy: 0.2525 - val_loss: 2.2788 - val_accuracy: 0.2269\n",
      "Epoch 8/10\n",
      "1365/1365 [==============================] - 19s 14ms/step - loss: 2.1469 - accuracy: 0.2615 - val_loss: 2.2990 - val_accuracy: 0.2240\n",
      "Epoch 9/10\n",
      "1365/1365 [==============================] - 20s 15ms/step - loss: 2.1074 - accuracy: 0.2743 - val_loss: 2.3785 - val_accuracy: 0.2209\n",
      "Epoch 10/10\n",
      "1365/1365 [==============================] - 18s 13ms/step - loss: 2.0690 - accuracy: 0.2835 - val_loss: 2.3704 - val_accuracy: 0.2026\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs = 10, validation_split=0.1, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[43660,951] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:GatherV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-77c4f3f8ea76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\acer\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    795\u001b[0m           data_adapter.train_validation_split((x, y, sample_weight),\n\u001b[0;32m    796\u001b[0m                                               \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m                                               shuffle=False))\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mtrain_validation_split\u001b[1;34m(arrays, validation_split, shuffle)\u001b[0m\n\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   train_arrays = nest.map_structure(\n\u001b[1;32m-> 1338\u001b[1;33m       functools.partial(_split, indices=train_indices), arrays)\n\u001b[0m\u001b[0;32m   1339\u001b[0m   val_arrays = nest.map_structure(\n\u001b[0;32m   1340\u001b[0m       functools.partial(_split, indices=val_indices), arrays)\n",
      "\u001b[1;32mc:\\users\\acer\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_split\u001b[1;34m(t, indices)\u001b[0m\n\u001b[0;32m   1333\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   train_arrays = nest.map_structure(\n",
      "\u001b[1;32mc:\\users\\acer\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[1;34m(params, indices, validate_indices, axis, batch_dims, name)\u001b[0m\n\u001b[0;32m   4539\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4540\u001b[0m       \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4541\u001b[1;33m       batch_dims=batch_dims)\n\u001b[0m\u001b[0;32m   4542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   4522\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4523\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4524\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[1;34m(params, indices, axis, batch_dims, name)\u001b[0m\n\u001b[0;32m   3753\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3754\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3755\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3756\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3757\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mbatch_dims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6652\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6653\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6654\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\anaconda3\\envs\\gpu\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[43660,951] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:GatherV2]"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs = 5, validation_split=0.1, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
